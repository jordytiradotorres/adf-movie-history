# ADF Movie History

Una soluciÃ³n **Enterprise** de procesamiento de datos de pelÃ­culas utilizando **Azure Data Factory (ADF)** que implementa una arquitectura moderna de data ingestion en capas (Bronze, Silver, Gold).

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#descripciÃ³n-general)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [TecnologÃ­as](#tecnologÃ­as)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Requisitos Previos](#requisitos-previos)
- [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
- [Pipelines Principales](#pipelines-principales)
- [Datasets](#datasets)
- [Linked Services](#linked-services)
- [Triggers](#triggers)
- [DocumentaciÃ³n](#documentaciÃ³n)

## ğŸ¯ DescripciÃ³n General

**ADF Movie History** es un proyecto de ingenierÃ­a de datos que automatiza el procesamiento, transformaciÃ³n y almacenamiento de informaciÃ³n histÃ³rica sobre pelÃ­culas. Utiliza Azure Data Factory para orquestar pipelines ETL (Extract, Transform, Load) que integran datos desde mÃºltiples fuentes hacia un data lake estructurado en capas.

El proyecto implementa las mejores prÃ¡cticas de arquitectura moderna de datos, asegurando escalabilidad, mantenibilidad y calidad de datos.

## âœ¨ CaracterÃ­sticas

- **Procesamiento en Capas (Medallion Architecture)**
  - **Bronze**: Ingesta bruta de datos sin transformar
  - **Silver**: Datos limpiados, validados y enriquecidos
  - **Gold**: Datos listos para anÃ¡lisis y reporting

- **AutomatizaciÃ³n Inteligente**
  - Pipelines programados automÃ¡ticamente mediante triggers
  - Monitoreo y alertas en tiempo real
  - Manejo robusto de errores y reintentos

- **Escalabilidad Enterprise**
  - Procesamiento de grandes volÃºmenes de datos
  - Optimizado para costos en Azure
  - Arquitectura modular y reutilizable

- **Calidad de Datos**
  - Validaciones integradas en cada capa
  - Trazabilidad completa de transformaciones
  - Versionado de datos y auditorÃ­a

- **OrquestaciÃ³n Centralizada**
  - Control total desde Azure Data Factory
  - Dependencias entre pipelines bien definidas
  - EjecuciÃ³n paralela cuando es posible

## ğŸ”§ TecnologÃ­as

| TecnologÃ­a | DescripciÃ³n | VersiÃ³n |
|-----------|-------------|---------|
| **Azure Data Factory** | Servicio ETL/ELT en la nube | Latest |
| **Azure Data Lake Storage Gen2** | Almacenamiento de datos escalable | Gen2 |
| **Azure SQL Database** | Base de datos relacional | SQL Server 2019+ |
| **Azure Synapse Analytics** | Data warehouse analÃ­tico (opcional) | - |
| **Power BI** | VisualizaciÃ³n y reporting (opcional) | Latest |
| **Git/GitHub** | Control de versiones | - |
| **JSON** | ConfiguraciÃ³n de pipelines | - |

## ğŸ“ Estructura del Proyecto

adf-movie-history/
â”œâ”€â”€ dataset/ # Definiciones de datasets
â”‚ â”œâ”€â”€ ds_data_history_bronze/ # Dataset de capa Bronze
â”‚ â”œâ”€â”€ ds_data_history_silver/ # Dataset de capa Silver
â”‚ â””â”€â”€ ds_data_history_gold/ # Dataset de capa Gold
â”‚
â”œâ”€â”€ factory/ # ConfiguraciÃ³n de la factorÃ­a ADF
â”‚ â””â”€â”€ adf-config.json # ConfiguraciÃ³n principal
â”‚
â”œâ”€â”€ linkedService/ # Conexiones a servicios externos
â”‚ â”œâ”€â”€ ls_azure_storage/ # Azure Data Lake Storage
â”‚ â”œâ”€â”€ ls_azure_sql_db/ # Azure SQL Database
â”‚ â””â”€â”€ ls_data_sources/ # Fuentes de datos externas
â”‚
â”œâ”€â”€ pipeline/ # Pipelines de procesamiento
â”‚ â”œâ”€â”€ pl_extract_movies/ # Extrae datos de fuentes
â”‚ â”œâ”€â”€ pl_transform_silver/ # Transforma a capa Silver
â”‚ â”œâ”€â”€ pl_transform_gold/ # Transforma a capa Gold
â”‚ â””â”€â”€ pl_main_orchestration/ # Orquesta todo el flujo
â”‚
â”œâ”€â”€ trigger/ # Triggers de ejecuciÃ³n
â”‚ â”œâ”€â”€ tr_daily_schedule/ # EjecuciÃ³n diaria programada
â”‚ â”œâ”€â”€ tr_event_based/ # Trigger basado en eventos
â”‚ â””â”€â”€ tr_manual/ # Trigger manual
â”‚
â”œâ”€â”€ README.md # Este archivo
â””â”€â”€ publish_config.json # ConfiguraciÃ³n de publicaciÃ³n


## ğŸ“‹ Requisitos Previos

Antes de comenzar, asegÃºrate de tener:

- **SuscripciÃ³n activa de Azure**
- **Credenciales de acceso** con permisos de:
  - Crear y gestionar Azure Data Factory
  - Acceder a Azure Data Lake Storage Gen2
  - Acceder a Azure SQL Database (si aplica)
- **Visual Studio Code** o **Azure Data Studio** (opcional, para desarrollo)
- **CLI de Azure** instalado (`az` command)
- **Git** para control de versiones

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/jordytiradotorres/adf-movie-history.git
cd adf-movie-history
```

### 2. Configurar Azure CLI

# Iniciar sesiÃ³n en Azure
az login

# Seleccionar suscripciÃ³n
az account set --subscription "Tu-ID-SuscripciÃ³n"

### 3. Importar en Azure Data Factory

1. Abre Azure Portal
2. Navega a tu instancia de Azure Data Factory
3. Ve a Autor â†’ Source Control
4. Conecta tu repositorio de GitHub
5. Importa todas las definiciones desde esta rama

### 4. Configurar Conexiones (Linked Services)

- Actualiza las credenciales en cada Linked Service
- Configura las cadenas de conexiÃ³n correctas para tus recursos Azure
- Prueba la conectividad desde ADF

### 5. Ejecutar Pipeline Principal

# Desplegar cambios desde el repositorio
az datafactory pipeline create-run \
  --resource-group "Tu-Grupo-Recursos" \
  --factory-name "Tu-FactorÃ­a-ADF" \
  --name "pl_main_orchestration"

### ğŸ“Š Pipelines Principales

- pl_extract_movies
Extrae datos de pelÃ­culas desde fuentes externas (APIs, bases de datos, archivos CSV) y los carga en la capa Bronze.

Entrada: APIs pÃºblicas o fuentes de datos
Salida: Archivos Parquet/JSON en Bronze Layer

- pl_transform_silver
Limpia, valida y enriquece los datos de la capa Bronze. Elimina duplicados, normaliza formatos y aplica reglas de negocio.

Entrada: Datos Bronze
Salida: Datos limpios en Silver Layer

- pl_transform_gold
Transforma datos Silver en modelos analÃ­ticos optimizados para reporting y dashboards.

Entrada: Datos Silver
Salida: Tablas agregadas en Gold Layer

- pl_main_orchestration
Orquesta la ejecuciÃ³n secuencial de todos los pipelines anteriores, garantizando dependencias y manejo de errores.

### ğŸ“¦ Datasets

- ds_data_history_bronze: Almacena datos crudos sin procesar
- ds_data_history_silver: Contiene datos transformados y validados
- ds_data_history_gold: Datasets listos para anÃ¡lisis y BI

## ğŸ”— Linked Services

- ls_azure_storage: ConexiÃ³n a Azure Data Lake Storage Gen2
- ls_azure_sql_db: ConexiÃ³n a Azure SQL Database
- ls_data_sources: Conexiones a fuentes externas de datos

## â²ï¸ Triggers

- tr_daily_schedule: Ejecuta pipelines diariamente a las 2:00 AM
- tr_event_based: Se activa cuando se detectan cambios en los datos
- tr_manual: Permite ejecuciÃ³n manual desde Azure Portal

## ğŸ“š DocumentaciÃ³n Adicional

Para mÃ¡s informaciÃ³n sobre Azure Data Factory:

DocumentaciÃ³n oficial de Azure Data Factory
Patrones de arquitectura ETL
Mejores prÃ¡cticas de Data Lake
Monitoreo y alertas en ADF
